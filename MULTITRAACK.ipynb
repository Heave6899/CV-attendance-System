{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-43dbcce3eaaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Initialize a face cascade using the frontal face haar cascade provided with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "\n",
    "\n",
    "#Initialize a face cascade using the frontal face haar cascade provided with\n",
    "#the OpenCV library\n",
    "faceCascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#The deisred output width and height\n",
    "OUTPUT_SIZE_WIDTH = 775\n",
    "OUTPUT_SIZE_HEIGHT = 600\n",
    "\n",
    "def detectAndTrackLargestFace():\n",
    "    #Open the first webcame device\n",
    "    capture = cv2.VideoCapture(0)\n",
    "\n",
    "    #Create two opencv named windows\n",
    "    cv2.namedWindow(\"base-image\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.namedWindow(\"result-image\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    #Position the windows next to eachother\n",
    "    cv2.moveWindow(\"base-image\",0,100)\n",
    "    cv2.moveWindow(\"result-image\",400,100)\n",
    "\n",
    "    #Start the window thread for the two windows we are using\n",
    "    cv2.startWindowThread()\n",
    "\n",
    "    #Create the tracker we will use\n",
    "    tracker = dlib.correlation_tracker()\n",
    "\n",
    "    #The variable we use to keep track of the fact whether we are\n",
    "    #currently using the dlib tracker\n",
    "    trackingFace = 0\n",
    "\n",
    "    #The color of the rectangle we draw around the face\n",
    "    rectangleColor = (0,165,255)\n",
    "\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            #Retrieve the latest image from the webcam\n",
    "            rc,fullSizeBaseImage = capture.read()\n",
    "\n",
    "            #Resize the image to 320x240\n",
    "            baseImage = cv2.resize( fullSizeBaseImage, ( 320, 240))\n",
    "\n",
    "\n",
    "            #Check if a key was pressed and if it was Q, then destroy all\n",
    "            #opencv windows and exit the application\n",
    "            pressedKey = cv2.waitKey(2)\n",
    "            if pressedKey == ord('Q'):\n",
    "                cv2.destroyAllWindows()\n",
    "                exit(0)\n",
    "\n",
    "\n",
    "\n",
    "            #Result image is the image we will show the user, which is a\n",
    "            #combination of the original image from the webcam and the\n",
    "            #overlayed rectangle for the largest face\n",
    "            resultImage = baseImage.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #If we are not tracking a face, then try to detect one\n",
    "            if not trackingFace:\n",
    "\n",
    "                #For the face detection, we need to make use of a gray\n",
    "                #colored image so we will convert the baseImage to a\n",
    "                #gray-based image\n",
    "                gray = cv2.cvtColor(baseImage, cv2.COLOR_BGR2GRAY)\n",
    "                #Now use the haar cascade detector to find all faces\n",
    "                #in the image\n",
    "                faces = faceCascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "                #In the console we can show that only now we are\n",
    "                #using the detector for a face\n",
    "                print(\"Using the cascade detector to detect face\")\n",
    "\n",
    "\n",
    "                #For now, we are only interested in the 'largest'\n",
    "                #face, and we determine this based on the largest\n",
    "                #area of the found rectangle. First initialize the\n",
    "                #required variables to 0\n",
    "                maxArea = 0\n",
    "                x = 0\n",
    "                y = 0\n",
    "                w = 0\n",
    "                h = 0\n",
    "\n",
    "\n",
    "                #Loop over all faces and check if the area for this\n",
    "                #face is the largest so far\n",
    "                #We need to convert it to int here because of the\n",
    "                #requirement of the dlib tracker. If we omit the cast to\n",
    "                #int here, you will get cast errors since the detector\n",
    "                #returns numpy.int32 and the tracker requires an int\n",
    "                for (_x,_y,_w,_h) in faces:\n",
    "                    if  _w*_h > maxArea:\n",
    "                        x = int(_x)\n",
    "                        y = int(_y)\n",
    "                        w = int(_w)\n",
    "                        h = int(_h)\n",
    "                        maxArea = w*h\n",
    "\n",
    "                #If one or more faces are found, initialize the tracker\n",
    "                #on the largest face in the picture\n",
    "                if maxArea > 0 :\n",
    "\n",
    "                    #Initialize the tracker\n",
    "                    tracker.start_track(baseImage,\n",
    "                                        dlib.rectangle( x-10,\n",
    "                                                        y-20,\n",
    "                                                        x+w+10,\n",
    "                                                        y+h+20))\n",
    "\n",
    "                    #Set the indicator variable such that we know the\n",
    "                    #tracker is tracking a region in the image\n",
    "                    trackingFace = 1\n",
    "\n",
    "            #Check if the tracker is actively tracking a region in the image\n",
    "            if trackingFace:\n",
    "\n",
    "                #Update the tracker and request information about the\n",
    "                #quality of the tracking update\n",
    "                trackingQuality = tracker.update( baseImage )\n",
    "\n",
    "\n",
    "\n",
    "                #If the tracking quality is good enough, determine the\n",
    "                #updated position of the tracked region and draw the\n",
    "                #rectangle\n",
    "                if trackingQuality >= 8.75:\n",
    "                    tracked_position =  tracker.get_position()\n",
    "\n",
    "                    t_x = int(tracked_position.left())\n",
    "                    t_y = int(tracked_position.top())\n",
    "                    t_w = int(tracked_position.width())\n",
    "                    t_h = int(tracked_position.height())\n",
    "                    cv2.rectangle(resultImage, (t_x, t_y),\n",
    "                                                (t_x + t_w , t_y + t_h),\n",
    "                                                rectangleColor ,2)\n",
    "\n",
    "                else:\n",
    "                    #If the quality of the tracking update is not\n",
    "                    #sufficient (e.g. the tracked region moved out of the\n",
    "                    #screen) we stop the tracking of the face and in the\n",
    "                    #next loop we will find the largest face in the image\n",
    "                    #again\n",
    "                    trackingFace = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #Since we want to show something larger on the screen than the\n",
    "            #original 320x240, we resize the image again\n",
    "            #\n",
    "            #Note that it would also be possible to keep the large version\n",
    "            #of the baseimage and make the result image a copy of this large\n",
    "            #base image and use the scaling factor to draw the rectangle\n",
    "            #at the right coordinates.\n",
    "            largeResult = cv2.resize(resultImage,\n",
    "                                     (OUTPUT_SIZE_WIDTH,OUTPUT_SIZE_HEIGHT))\n",
    "\n",
    "            #Finally, we want to show the images on the screen\n",
    "            cv2.imshow(\"base-image\", baseImage)\n",
    "            cv2.imshow(\"result-image\", largeResult)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #To ensure we can also deal with the user pressing Ctrl-C in the console\n",
    "    #we have to check for the KeyboardInterrupt exception and destroy\n",
    "    #all opencv windows and exit the application\n",
    "    except KeyboardInterrupt as e:\n",
    "        cv2.destroyAllWindows()\n",
    "        exit(0)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    detectAndTrackLargestFace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
